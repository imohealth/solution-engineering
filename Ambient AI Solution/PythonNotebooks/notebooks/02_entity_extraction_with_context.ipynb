{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee17da42",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/imohealth/solution-engineering/refs/heads/updates/Ambient%20AI%20Solution/PythonNotebooks/static/imo_health.png?token=GHSAT0AAAAAADSTDGZJSTP4JZ4FRZXRUZUW2LYZ3WA\" alt=\"IMO Health Logo\" width=\"300\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Configuration\n",
    "\n",
    "Import libraries and load the SOAP note from Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0ec6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Import configuration\n",
    "import config\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a87e4",
   "metadata": {},
   "source": [
    "## Load SOAP Note from Step 1\n",
    "\n",
    "Load the SOAP note generated in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf01d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP note from Step 1\n",
    "soap_file = 'soap_note_output.json'\n",
    "\n",
    "try:\n",
    "    with open(soap_file, 'r') as f:\n",
    "        soap_note = json.load(f)\n",
    "    \n",
    "    print(\"✓ SOAP note loaded successfully\")\n",
    "    print(f\"\\nSOAP Note Sections:\")\n",
    "    print(f\"  Subjective: {len(soap_note['subjective'])} characters\")\n",
    "    print(f\"  Objective: {len(soap_note['objective'])} characters\")\n",
    "    print(f\"  Assessment: {len(soap_note['assessment'])} characters\")\n",
    "    print(f\"  Plan: {len(soap_note['plan'])} characters\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ Error: {soap_file} not found\")\n",
    "    print(\"  Please run Step 1 notebook first to generate the SOAP note\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030f720",
   "metadata": {},
   "source": [
    "## Prepare Text for Entity Extraction\n",
    "\n",
    "We'll extract entities from the **Assessment** and **Plan** sections, as these contain the most clinically relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64da9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Assessment and Plan sections\n",
    "assessment_plan_text = soap_note['assessment'] + '\\n\\n' + soap_note['plan']\n",
    "\n",
    "print(\"Text for Entity Extraction:\")\n",
    "print(\"=\" * 80)\n",
    "print(assessment_plan_text)\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal length: {len(assessment_plan_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e90a8f",
   "metadata": {},
   "source": [
    "## Configure IMO API Access\n",
    "\n",
    "Set up authentication for IMO Entity Extraction API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class IMOAuthenticator:\n",
    "    \"\"\"Handle IMO API authentication.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.auth_url = config.imo_auth_url if hasattr(config, 'imo_auth_url') else \"https://auth.imohealth.com/oauth/token\"\n",
    "        self.client_id = config.imo_entity_extraction_client_id\n",
    "        self.client_secret = config.imo_entity_extraction_client_secret\n",
    "        self.client_secret = config.imo_normalize_enrichment_api_client_secret\n",
    "        self.access_token = None\n",
    "        self.token_expiry = None\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Get or refresh OAuth access token.\"\"\"\n",
    "        # Return cached token if still valid\n",
    "        if self.access_token and self.token_expiry and time.time() < self.token_expiry:\n",
    "            return self.access_token\n",
    "        \n",
    "        print(\"Requesting new access token from IMO OAuth endpoint...\")\n",
    "        \n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        payload = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'client_id': self.client_id,\n",
    "            'client_secret': self.client_secret,\n",
    "            'audience': 'https://api.imohealth.com'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.auth_url, headers=headers, json=payload, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                self.access_token = result.get('access_token')\n",
    "                expires_in = result.get('expires_in', 3600)\n",
    "                self.token_expiry = time.time() + expires_in - 60\n",
    "                print(f\"✓ Access token obtained (expires in {expires_in}s)\")\n",
    "                return self.access_token\n",
    "            else:\n",
    "                print(f\"✗ OAuth Error: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error getting access token: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Initialize authenticator\n",
    "authenticator = IMOAuthenticator()\n",
    "print(\"✓ IMO Authenticator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3235531f",
   "metadata": {},
   "source": [
    "## Extract Entities with IMO API\n",
    "\n",
    "Call the IMO Entity Extraction API to identify medical entities in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd042946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_with_context(text, context_chars=200):\n",
    "    \"\"\"\n",
    "    Extract medical entities from text using IMO Entity Extraction API.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Medical text to analyze\n",
    "        context_chars (int): Number of characters to capture around each entity\n",
    "        \n",
    "    Returns:\n",
    "        dict: Categorized entities with context\n",
    "    \"\"\"\n",
    "    # Get access token\n",
    "    access_token = authenticator.get_access_token()\n",
    "    if not access_token:\n",
    "        raise Exception(\"Failed to obtain IMO API access token\")\n",
    "    \n",
    "    # API endpoint\n",
    "    entity_extraction_url = config.imo_entity_extraction_url if hasattr(config, 'imo_entity_extraction_url') else \"https://api.imohealth.com/entityextraction/pipelines/imo-clinical-comprehensive\"\n",
    "    \n",
    "    # Prepare request\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    \n",
    "    payload = {'text': text}\n",
    "    \n",
    "    print(f\"\\nCalling IMO Entity Extraction API...\")\n",
    "    print(f\"Endpoint: {entity_extraction_url}\")\n",
    "    print(f\"Text length: {len(text)} characters\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            entity_extraction_url,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"✓ Successfully extracted entities\")\n",
    "            print(f\"  Total entities found: {len(result.get('entities', []))}\")\n",
    "            \n",
    "            # Parse and categorize entities\n",
    "            return parse_entities_with_context(result, text, context_chars)\n",
    "        else:\n",
    "            print(f\"✗ API Error: {response.status_code} - {response.text}\")\n",
    "            raise Exception(f\"API returned status {response.status_code}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error calling Entity Extraction API: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def extract_context(text, offset, length, context_window=200):\n",
    "    \"\"\"\n",
    "    Extract context around an entity in the text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Full text\n",
    "        offset (int): Starting position of entity\n",
    "        length (int): Length of entity\n",
    "        context_window (int): Number of characters before/after to include\n",
    "        \n",
    "    Returns:\n",
    "        str: Context string\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    start = max(0, offset - context_window)\n",
    "    end = min(len(text), offset + length + context_window)\n",
    "    \n",
    "    context = text[start:end].strip()\n",
    "    \n",
    "    # Add ellipsis if context is truncated\n",
    "    if start > 0:\n",
    "        context = \"...\" + context\n",
    "    if end < len(text):\n",
    "        context = context + \"...\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "def parse_entities_with_context(api_response, original_text, context_chars=200):\n",
    "    \"\"\"\n",
    "    Parse API response and extract context around each entity.\n",
    "    \n",
    "    Args:\n",
    "        api_response (dict): IMO API response\n",
    "        original_text (str): Original text for context extraction\n",
    "        context_chars (int): Characters to capture around entity\n",
    "        \n",
    "    Returns:\n",
    "        dict: Categorized entities with context\n",
    "    \"\"\"\n",
    "    entities = {\n",
    "        'problems': [],\n",
    "        'procedures': [],\n",
    "        'medications': [],\n",
    "        'labs': []\n",
    "    }\n",
    "    \n",
    "    # Ignore generic/administrative terms\n",
    "    ignore_patterns = [\n",
    "        'review test results', 'patient education', 'lifestyle',\n",
    "        'education', 'review', 'follow-up', 'follow up',\n",
    "        'appointment', 'monitoring', 'discussion', 'counseling',\n",
    "        'instructions', 'recommendations', 'assessment', 'plan'\n",
    "    ]\n",
    "    \n",
    "    for entity in api_response.get('entities', []):\n",
    "        # Only include entities with assertion \"present\"\n",
    "        assertion = entity.get('assertion', '').lower()\n",
    "        if assertion != 'present':\n",
    "            print(f\"  Skipping entity '{entity.get('text', '')}' with assertion '{assertion}'\")\n",
    "            continue\n",
    "        \n",
    "        # Skip generic entities\n",
    "        entity_text = entity.get('text', '').lower().strip()\n",
    "        if any(pattern in entity_text for pattern in ignore_patterns):\n",
    "            print(f\"  Ignoring generic entity: '{entity.get('text', '')}'\")\n",
    "            continue\n",
    "        \n",
    "        # Get entity position\n",
    "        category = entity.get('semantic', '').lower()\n",
    "        offset = entity.get('begin', 0)\n",
    "        end_offset = entity.get('end', 0)\n",
    "        length = end_offset - offset\n",
    "        \n",
    "        # Extract context around the entity\n",
    "        context = extract_context(original_text, offset, length, context_window=context_chars)\n",
    "        \n",
    "        # Extract IMO code from codemaps\n",
    "        imo_code = ''\n",
    "        imo_description = ''\n",
    "        confidence = 0.0\n",
    "        \n",
    "        if 'codemaps' in entity and 'imo' in entity['codemaps']:\n",
    "            imo_data = entity['codemaps']['imo']\n",
    "            imo_code = imo_data.get('lexical_code', '')\n",
    "            imo_description = imo_data.get('lexical_title', '')\n",
    "            confidence = float(imo_data.get('confidence', 0.0))\n",
    "        \n",
    "        # Create entity record\n",
    "        entity_record = {\n",
    "            'text': entity.get('text', ''),\n",
    "            'code': imo_code,\n",
    "            'code_system': 'IMO',\n",
    "            'description': imo_description,\n",
    "            'offset': offset,\n",
    "            'length': length,\n",
    "            'confidence': confidence,\n",
    "            'context': context,\n",
    "            'context_length': len(context),\n",
    "            'entity_id': entity.get('id', ''),\n",
    "            'semantic': entity.get('semantic', ''),\n",
    "            'assertion': assertion,\n",
    "            'codemaps': entity.get('codemaps', {})\n",
    "        }\n",
    "        \n",
    "        # Map categories based on semantic type\n",
    "        if 'problem' in category or 'condition' in category or 'diagnosis' in category:\n",
    "            entities['problems'].append(entity_record)\n",
    "        elif 'procedure' in category:\n",
    "            entities['procedures'].append(entity_record)\n",
    "        elif 'medication' in category or 'drug' in category:\n",
    "            entities['medications'].append(entity_record)\n",
    "        elif 'lab' in category or 'observation' in category or 'test' in category:\n",
    "            entities['labs'].append(entity_record)\n",
    "        else:\n",
    "            # Default to problems for unknown categories\n",
    "            print(f\"  Unknown category '{category}' for entity '{entity.get('text', '')}'\")\n",
    "            #entities['problems'].append(entity_record)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Extract entities\n",
    "extracted_entities = extract_entities_with_context(assessment_plan_text, context_chars=200)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENTITY EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Problems: {len(extracted_entities['problems'])}\")\n",
    "print(f\"Procedures: {len(extracted_entities['procedures'])}\")\n",
    "print(f\"Medications: {len(extracted_entities['medications'])}\")\n",
    "print(f\"Labs: {len(extracted_entities['labs'])}\")\n",
    "print(f\"\\nTotal entities: {sum(len(v) for v in extracted_entities.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0389d3c",
   "metadata": {},
   "source": [
    "## Display Extracted Entities with Context\n",
    "\n",
    "Show all extracted entities organized by category, including their contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_entities(entities_dict):\n",
    "    \"\"\"Display entities in a readable format.\"\"\"\n",
    "    \n",
    "    for category, entity_list in entities_dict.items():\n",
    "        if not entity_list:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"{category.upper()} ({len(entity_list)} entities)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, entity in enumerate(entity_list, 1):\n",
    "            print(f\"\\n{i}. {entity['text']}\")\n",
    "            print(f\"   Semantic: {entity.get('semantic', 'N/A')}\")\n",
    "            print(f\"   Assertion: {entity['assertion']}\")\n",
    "            print(f\"   Confidence: {entity.get('confidence', 0):.2f}\")\n",
    "            \n",
    "            if entity.get('code'):\n",
    "                print(f\"   IMO Code: {entity['code']}\")\n",
    "            if entity.get('description'):\n",
    "                print(f\"   IMO Description: {entity['description']}\")\n",
    "            \n",
    "            print(f\"\\n   Context ({entity['context_length']} chars):\")\n",
    "            print(f\"   {entity['context']}\")\n",
    "            \n",
    "            # Display codemaps if available\n",
    "            if entity.get('codemaps'):\n",
    "                print(f\"\\n   Available Code Systems:\")\n",
    "                for system in entity['codemaps'].keys():\n",
    "                    print(f\"     - {system.upper()}\")\n",
    "            \n",
    "            print(\"-\" * 80)\n",
    "\n",
    "# Display all entities\n",
    "display_entities(extracted_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac2352",
   "metadata": {},
   "source": [
    "## Analyze Context Quality\n",
    "\n",
    "Evaluate the quality and usefulness of extracted contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def analyze_context_quality(entities_dict):\n",
    "    \"\"\"Analyze the quality of extracted contexts.\"\"\"\n",
    "    \n",
    "    all_contexts = []\n",
    "    for entity_list in entities_dict.values():\n",
    "        for entity in entity_list:\n",
    "            all_contexts.append(entity['context_length'])\n",
    "    \n",
    "    if all_contexts:\n",
    "        print(\"Context Quality Analysis:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total entities with context: {len(all_contexts)}\")\n",
    "        print(f\"Average context length: {statistics.mean(all_contexts):.1f} characters\")\n",
    "        print(f\"Median context length: {statistics.median(all_contexts):.1f} characters\")\n",
    "        print(f\"Min context length: {min(all_contexts)} characters\")\n",
    "        print(f\"Max context length: {max(all_contexts)} characters\")\n",
    "        print(f\"\\nContext captures: ~{statistics.mean(all_contexts)/2:.0f} chars before + ~{statistics.mean(all_contexts)/2:.0f} chars after entity\")\n",
    "    else:\n",
    "        print(\"No entities found\")\n",
    "\n",
    "analyze_context_quality(extracted_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194370a",
   "metadata": {},
   "source": [
    "## Save Extracted Entities\n",
    "\n",
    "Save the entities with context to a JSON file for use in Step 3 (Normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output structure\n",
    "entities_output = {\n",
    "    'entities': extracted_entities,\n",
    "    'extraction_metadata': {\n",
    "        'total_entities': sum(len(v) for v in extracted_entities.values()),\n",
    "        'problems_count': len(extracted_entities['problems']),\n",
    "        'procedures_count': len(extracted_entities['procedures']),\n",
    "        'medications_count': len(extracted_entities['medications']),\n",
    "        'labs_count': len(extracted_entities['labs']),\n",
    "        'context_chars': 200,\n",
    "        'extracted_at': datetime.now().isoformat(),\n",
    "        'source_text_length': len(assessment_plan_text)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "output_file = 'extracted_entities_output.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(entities_output, f, indent=2)\n",
    "\n",
    "print(f\"✓ Extracted entities saved to: {output_file}\")\n",
    "print(f\"\\nOutput includes:\")\n",
    "print(f\"  - {entities_output['extraction_metadata']['total_entities']} entities\")\n",
    "print(f\"  - Context for each entity (~200 chars)\")\n",
    "print(f\"  - IMO codes and titles\")\n",
    "print(f\"  - Standard code mappings (ICD-10, SNOMED, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ebb535",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. ✓ Loaded SOAP note from Step 1\n",
    "2. ✓ Extracted Assessment and Plan sections for entity analysis\n",
    "3. ✓ Called IMO Entity Extraction API\n",
    "4. ✓ Categorized entities into problems, procedures, medications, and labs\n",
    "5. ✓ Captured 200 characters of context around each entity\n",
    "6. ✓ Filtered out generic/administrative terms\n",
    "7. ✓ Saved entities with context for normalization\n",
    "\n",
    "### Context Examples\n",
    "\n",
    "Context helps with:\n",
    "- **Clinical relevance**: \"chest pain\" with context \"heavy pressure radiating to left arm\" vs. \"resolved chest pain\"\n",
    "- **Specificity**: \"diabetes\" with context \"type 2 diabetes mellitus for 8 years\"\n",
    "- **Relationships**: \"aspirin\" with context \"aspirin 325mg chewed immediately\"\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The extracted entities will be used in **Step 3: Normalization with Enrichment**, where we'll:\n",
    "- Normalize entities to standard medical terminologies\n",
    "- Enrich with additional clinical metadata\n",
    "- Use IMO Precision Normalize API\n",
    "- Prepare data for diagnostic specificity workflow\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **IMO Entity Extraction** provides high-accuracy medical entity recognition\n",
    "- **Context** is crucial for understanding clinical intent\n",
    "- **Assertion filtering** ensures we focus on present conditions\n",
    "- **Categorization** organizes entities by clinical domain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
