{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c18ffb6",
   "metadata": {},
   "source": [
    "<img src=\"../static/imo_health.png\" alt=\"IMO Health Logo\" width=\"300\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Configuration\n",
    "\n",
    "Import libraries and load the extracted entities from Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Import configuration\n",
    "import config\n",
    "\n",
    "# Import authenticator from Step 2\n",
    "import time\n",
    "\n",
    "class IMOAuthenticator:\n",
    "    \"\"\"Handle IMO API authentication.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.auth_url = config.imo_auth_url if hasattr(config, 'imo_auth_url') else \"https://auth.imohealth.com/oauth/token\"\n",
    "        self.client_id = config.imo_normalize_enrichment_api_client_id\n",
    "        self.client_secret = config.imo_normalize_enrichment_api_client_secret\n",
    "        self.access_token = None\n",
    "        self.token_expiry = None\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Get or refresh OAuth access token.\"\"\"\n",
    "        if self.access_token and self.token_expiry and time.time() < self.token_expiry:\n",
    "            return self.access_token\n",
    "        \n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        payload = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'client_id': self.client_id,\n",
    "            'client_secret': self.client_secret,\n",
    "            'audience': 'https://api.imohealth.com'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.auth_url, headers=headers, json=payload, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                self.access_token = result.get('access_token')\n",
    "                expires_in = result.get('expires_in', 3600)\n",
    "                self.token_expiry = time.time() + expires_in - 60\n",
    "                return self.access_token\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting access token: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "authenticator = IMOAuthenticator()\n",
    "print(\"✓ Libraries imported and authenticator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc9f0e",
   "metadata": {},
   "source": [
    "## Load Extracted Entities from Step 2\n",
    "\n",
    "Load the entities with context that were extracted in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted entities from Step 2\n",
    "entities_file = 'extracted_entities_output.json'\n",
    "\n",
    "try:\n",
    "    with open(entities_file, 'r') as f:\n",
    "        entities_data = json.load(f)\n",
    "    \n",
    "    extracted_entities = entities_data['entities']\n",
    "    metadata = entities_data['extraction_metadata']\n",
    "    \n",
    "    print(\"✓ Extracted entities loaded successfully\")\n",
    "    print(f\"\\nEntity Counts:\")\n",
    "    print(f\"  Problems: {metadata['problems_count']}\")\n",
    "    print(f\"  Procedures: {metadata['procedures_count']}\")\n",
    "    print(f\"  Medications: {metadata['medications_count']}\")\n",
    "    print(f\"  Labs: {metadata['labs_count']}\")\n",
    "    print(f\"  Total: {metadata['total_entities']}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ Error: {entities_file} not found\")\n",
    "    print(\"  Please run Step 2 notebook first to extract entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87afcb8",
   "metadata": {},
   "source": [
    "## Normalize Entities with IMO Precision Normalize API\n",
    "\n",
    "Call the IMO Precision Normalize API to normalize and enrich entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def normalize_single_entity(entity, category, access_token):\n",
    "    \"\"\"\n",
    "    Normalize a single entity using IMO API.\n",
    "    Uses enrichment endpoint for problems (with context), regular endpoint for others.\n",
    "    \n",
    "    Args:\n",
    "        entity (dict): Entity to normalize\n",
    "        category (str): Entity category (problems, procedures, medications, labs)\n",
    "        access_token (str): OAuth access token\n",
    "        \n",
    "    Returns:\n",
    "        dict: Normalized entity\n",
    "    \"\"\"\n",
    "    # Map category to domain\n",
    "    domain_map = {\n",
    "        'problems': 'problem',\n",
    "        'procedures': 'procedure',\n",
    "        'medications': 'medication',\n",
    "        'labs': 'lab'\n",
    "    }\n",
    "    domain = domain_map.get(category, 'problem')\n",
    "    \n",
    "    # Use enrichment endpoint for problems, regular for others\n",
    "    if category == 'problems':\n",
    "        url = config.imo_precision_normalize_enrichment_url if hasattr(config, 'imo_precision_normalize_enrichment_url') else \"https://api.imohealth.com/precision/normalize/enrichment\"\n",
    "        \n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "        \n",
    "        # Build enrichment payload with context\n",
    "        payload = {\n",
    "            \"organization_id\": \"IMO\",\n",
    "            \"client_request_id\": str(uuid.uuid4()),\n",
    "            \"preferences\": {\n",
    "                \"threshold\": 0.0,\n",
    "                \"match_field_pref\": \"input_term\",\n",
    "                \"debug\": True\n",
    "            },\n",
    "            \"requests\": [{\n",
    "                \"record_id\": entity.get('entity_id', str(uuid.uuid4())),\n",
    "                \"domain\": domain,\n",
    "                \"input_term\": entity.get('text', ''),\n",
    "                \"context\": {\n",
    "                    \"source_text\": entity.get('context', '')\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Normalizing problem with enrichment: {entity.get('text', '')}\")\n",
    "        \n",
    "    else:\n",
    "        # Use regular normalize endpoint for other domains\n",
    "        url = config.imo_precision_normalize_url if hasattr(config, 'imo_precision_normalize_url') else \"https://api.imohealth.com/precision/normalize\"\n",
    "        \n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"organization_id\": \"IMO\",\n",
    "            \"client_request_id\": str(uuid.uuid4()),\n",
    "            \"preferences\": {\n",
    "                \"threshold\": 0.0,\n",
    "                \"match_field_pref\": \"input_term\",\n",
    "                \"debug\": True\n",
    "            },\n",
    "            \"requests\": [{\n",
    "                \"record_id\": entity.get('entity_id', str(uuid.uuid4())),\n",
    "                \"domain\": domain,\n",
    "                \"input_term\": entity.get('text', ''),\n",
    "                \"input_code\": entity.get('code', ''),\n",
    "                \"input_code_system\": entity.get('code_system', '')\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Normalizing {category} entity: {entity.get('text', '')}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Parse IMO normalization response\n",
    "            if 'requests' in result and len(result['requests']) > 0:\n",
    "                request_data = result['requests'][0]\n",
    "                \n",
    "                # Check if response exists and has items\n",
    "                if 'response' in request_data and 'items' in request_data['response']:\n",
    "                    items = request_data['response']['items']\n",
    "                    \n",
    "                    if len(items) > 0:\n",
    "                        # Get top match (first item)\n",
    "                        top_match = items[0]\n",
    "                        \n",
    "                        entity['imo_code'] = top_match.get('code', '')\n",
    "                        entity['imo_lexical_code'] = top_match.get('lexical_code', '')\n",
    "                        entity['imo_description'] = top_match.get('title', '')\n",
    "                        entity['imo_lexical_title'] = top_match.get('lexical_title', '')\n",
    "                        entity['normalized'] = True\n",
    "                        entity['normalization_confidence'] = top_match.get('score', 0.0)\n",
    "                        \n",
    "                        # Check if refinable (from flags)\n",
    "                        metadata = top_match.get('metadata', {})\n",
    "                        flags = metadata.get('flags', {})\n",
    "                        entity['is_refinable'] = flags.get('is_icd10cm_refinable', False)\n",
    "                        entity['needs_refinement'] = entity['is_refinable']\n",
    "                        \n",
    "                        # Store mappings based on category\n",
    "                        mappings = metadata.get('mappings', {})\n",
    "                        \n",
    "                        # ICD-10-CM for problems\n",
    "                        icd10cm_codes = mappings.get('icd10cm', {}).get('codes', [])\n",
    "                        if icd10cm_codes:\n",
    "                            entity['icd10cm_code'] = icd10cm_codes[0].get('code', '')\n",
    "                            entity['icd10cm_title'] = icd10cm_codes[0].get('title', '')\n",
    "                        \n",
    "                        # CPT for procedures\n",
    "                        cpt_codes = mappings.get('cpt', {}).get('codes', [])\n",
    "                        if cpt_codes:\n",
    "                            entity['cpt_code'] = cpt_codes[0].get('code', '')\n",
    "                            entity['cpt_title'] = cpt_codes[0].get('title', '')\n",
    "                        \n",
    "                        # RxNorm for medications\n",
    "                        rxnorm_codes = mappings.get('rxnorm', {}).get('codes', [])\n",
    "                        if rxnorm_codes:\n",
    "                            entity['rxnorm_code'] = rxnorm_codes[0].get('code', '')\n",
    "                            entity['rxnorm_title'] = rxnorm_codes[0].get('title', '')\n",
    "                        \n",
    "                        # LOINC for labs\n",
    "                        loinc_codes = mappings.get('loinc', {}).get('codes', [])\n",
    "                        if loinc_codes:\n",
    "                            entity['loinc_code'] = loinc_codes[0].get('code', '')\n",
    "                            entity['loinc_title'] = loinc_codes[0].get('title', '')\n",
    "                        \n",
    "                        # Store alternate choices\n",
    "                        alternate_choices = []\n",
    "                        for alt_item in items[1:]:\n",
    "                            alt_choice = {\n",
    "                                'imo_code': alt_item.get('code', ''),\n",
    "                                'lexical_code': alt_item.get('lexical_code', ''),\n",
    "                                'title': alt_item.get('title', ''),\n",
    "                                'lexical_title': alt_item.get('lexical_title', ''),\n",
    "                                'score': alt_item.get('score', 0.0),\n",
    "                                'is_refinable': alt_item.get('metadata', {}).get('flags', {}).get('is_icd10cm_refinable', False)\n",
    "                            }\n",
    "                            \n",
    "                            # Add category-specific codes if available\n",
    "                            alt_mappings = alt_item.get('metadata', {}).get('mappings', {})\n",
    "                            \n",
    "                            # ICD-10-CM\n",
    "                            alt_icd10cm = alt_mappings.get('icd10cm', {}).get('codes', [])\n",
    "                            if alt_icd10cm:\n",
    "                                alt_choice['icd10cm_code'] = alt_icd10cm[0].get('code', '')\n",
    "                                alt_choice['icd10cm_title'] = alt_icd10cm[0].get('title', '')\n",
    "                            \n",
    "                            alternate_choices.append(alt_choice)\n",
    "                        \n",
    "                        entity['alternate_choices'] = alternate_choices\n",
    "                        \n",
    "                        # Log result\n",
    "                        refinable_tag = \" [REFINABLE]\" if entity['is_refinable'] else \"\"\n",
    "                        print(f\"    ✓ Normalized to IMO: {entity['imo_code']} - {entity['imo_description']}{refinable_tag}\")\n",
    "                        if alternate_choices:\n",
    "                            print(f\"      Alternate choices: {len(alternate_choices)}\")\n",
    "                    else:\n",
    "                        entity['normalized'] = False\n",
    "                        entity['needs_refinement'] = False\n",
    "                        entity['is_refinable'] = False\n",
    "                        entity['alternate_choices'] = []\n",
    "                else:\n",
    "                    entity['normalized'] = False\n",
    "                    entity['needs_refinement'] = False\n",
    "                    entity['is_refinable'] = False\n",
    "                    entity['alternate_choices'] = []\n",
    "            else:\n",
    "                entity['normalized'] = False\n",
    "                entity['needs_refinement'] = False\n",
    "                entity['is_refinable'] = False\n",
    "                entity['alternate_choices'] = []\n",
    "                \n",
    "            return entity\n",
    "            \n",
    "        else:\n",
    "            print(f\"    ✗ API Error: {response.status_code}\")\n",
    "            entity['normalized'] = False\n",
    "            entity['needs_refinement'] = False\n",
    "            return entity\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error: {str(e)}\")\n",
    "        entity['normalized'] = False\n",
    "        entity['needs_refinement'] = False\n",
    "        return entity\n",
    "\n",
    "def normalize_entities(entities_dict):\n",
    "    \"\"\"\n",
    "    Normalize entities using IMO Precision Normalize API.\n",
    "    \n",
    "    Args:\n",
    "        entities_dict (dict): Extracted entities\n",
    "        \n",
    "    Returns:\n",
    "        dict: Normalized entities with IMO codes\n",
    "    \"\"\"\n",
    "    # Get OAuth access token\n",
    "    access_token = authenticator.get_access_token()\n",
    "    if not access_token:\n",
    "        raise Exception(\"Failed to obtain IMO API access token\")\n",
    "    \n",
    "    normalized = {\n",
    "        'problems': [],\n",
    "        'procedures': [],\n",
    "        'medications': [],\n",
    "        'labs': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nNormalizing entities...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Normalize each category\n",
    "    for category, entity_list in entities_dict.items():\n",
    "        if not entity_list:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{category.upper()} ({len(entity_list)} entities):\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for entity in entity_list:\n",
    "            try:\n",
    "                normalized_entity = normalize_single_entity(entity, category, access_token)\n",
    "                normalized[category].append(normalized_entity)\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error normalizing entity {entity.get('text')}: {str(e)}\")\n",
    "                # Add original entity if normalization fails\n",
    "                entity['normalized'] = False\n",
    "                entity['needs_refinement'] = False\n",
    "                normalized[category].append(entity)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# Normalize entities\n",
    "normalized_entities = normalize_entities(extracted_entities)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NORMALIZATION COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc381c8c",
   "metadata": {},
   "source": [
    "## Analyze Normalization Results\n",
    "\n",
    "Analyze the normalized entities and enrichment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_normalization(normalized_dict):\n",
    "    \"\"\"\n",
    "    Analyze normalization results.\n",
    "    \n",
    "    Args:\n",
    "        normalized_dict (dict): Normalized entities\n",
    "    \"\"\"\n",
    "    total = sum(len(v) for v in normalized_dict.values())\n",
    "    successfully_normalized = sum(1 for entities in normalized_dict.values() \n",
    "                                  for e in entities if e.get('normalized', False))\n",
    "    failed = total - successfully_normalized\n",
    "    \n",
    "    # Count entities with refinement flags\n",
    "    needs_refinement = sum(1 for entities in normalized_dict.values()\n",
    "                          for e in entities if e.get('needs_refinement', False))\n",
    "    \n",
    "    print(\"Normalization Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total entities: {total}\")\n",
    "    print(f\"Successfully normalized: {successfully_normalized} ({successfully_normalized/total*100:.1f}%)\")\n",
    "    print(f\"Failed normalization: {failed}\")\n",
    "    print(f\"Needs refinement: {needs_refinement} ({needs_refinement/total*100:.1f}%)\")\n",
    "    \n",
    "    # Count by category\n",
    "    print(f\"\\nBy Category:\")\n",
    "    for category, entities in normalized_dict.items():\n",
    "        normalized_count = sum(1 for e in entities if e.get('normalized', False))\n",
    "        refinable_count = sum(1 for e in entities if e.get('is_refinable', False))\n",
    "        print(f\"  {category.title()}: {len(entities)} total, {normalized_count} normalized, {refinable_count} refinable\")\n",
    "\n",
    "analyze_normalization(normalized_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cca0fb",
   "metadata": {},
   "source": [
    "## Display Normalized Entities with Enrichment\n",
    "\n",
    "Show normalized entities with their standard codes and enrichment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed106bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_normalized_entities(normalized_dict, max_display=5):\n",
    "    \"\"\"\n",
    "    Display normalized entities with enrichment.\n",
    "    \n",
    "    Args:\n",
    "        normalized_dict (dict): Normalized entities\n",
    "        max_display (int): Maximum entities to display per category\n",
    "    \"\"\"\n",
    "    for category, entity_list in normalized_dict.items():\n",
    "        if not entity_list:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"{category.upper()} ({len(entity_list)} entities)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, entity in enumerate(entity_list[:max_display], 1):\n",
    "            print(f\"\\n{i}. {entity['text']}\")\n",
    "            \n",
    "            if entity.get('normalized', False):\n",
    "                print(f\"   ✓ Normalized successfully\")\n",
    "                print(f\"   IMO Code: {entity.get('imo_lexical_code', 'N/A')}\")\n",
    "                print(f\"   IMO Description: {entity.get('imo_lexical_title', 'N/A')}\")\n",
    "                print(f\"   Confidence: {entity.get('normalization_confidence', 0):.2f}\")\n",
    "                \n",
    "                # Display category-specific codes\n",
    "                if category == 'problems' and entity.get('icd10cm_code'):\n",
    "                    print(f\"\\n   ICD-10-CM:\")\n",
    "                    print(f\"     Code: {entity.get('icd10cm_code', 'N/A')}\")\n",
    "                    print(f\"     Title: {entity.get('icd10cm_title', 'N/A')}\")\n",
    "                \n",
    "                elif category == 'procedures' and entity.get('cpt_code'):\n",
    "                    print(f\"\\n   CPT:\")\n",
    "                    print(f\"     Code: {entity.get('cpt_code', 'N/A')}\")\n",
    "                    print(f\"     Title: {entity.get('cpt_title', 'N/A')}\")\n",
    "                \n",
    "                elif category == 'medications' and entity.get('rxnorm_code'):\n",
    "                    print(f\"\\n   RxNorm:\")\n",
    "                    print(f\"     Code: {entity.get('rxnorm_code', 'N/A')}\")\n",
    "                    print(f\"     Title: {entity.get('rxnorm_title', 'N/A')}\")\n",
    "                \n",
    "                elif category == 'labs' and entity.get('loinc_code'):\n",
    "                    print(f\"\\n   LOINC:\")\n",
    "                    print(f\"     Code: {entity.get('loinc_code', 'N/A')}\")\n",
    "                    print(f\"     Title: {entity.get('loinc_title', 'N/A')}\")\n",
    "                \n",
    "                # Display refinement flag\n",
    "                if entity.get('is_refinable', False):\n",
    "                    print(f\"\\n   ⚠️  IS REFINABLE - Needs diagnostic specificity workflow\")\n",
    "                \n",
    "                # Display alternate choices if available\n",
    "                alternate_choices = entity.get('alternate_choices', [])\n",
    "                if alternate_choices:\n",
    "                    print(f\"\\n   Alternate Choices ({len(alternate_choices)}):\")\n",
    "                    for j, alt in enumerate(alternate_choices[:3], 1):\n",
    "                        refinable_marker = \" [REFINABLE]\" if alt.get('is_refinable', False) else \"\"\n",
    "                        print(f\"     {j}. {alt.get('lexical_title', 'N/A')} (Score: {alt.get('score', 0):.2f}){refinable_marker}\")\n",
    "                    if len(alternate_choices) > 3:\n",
    "                        print(f\"     ... and {len(alternate_choices) - 3} more\")\n",
    "            else:\n",
    "                print(f\"   ✗ Normalization failed\")\n",
    "            \n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        if len(entity_list) > max_display:\n",
    "            print(f\"\\n... and {len(entity_list) - max_display} more entities\")\n",
    "\n",
    "# Display normalized entities\n",
    "display_normalized_entities(normalized_entities, max_display=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d9edd",
   "metadata": {},
   "source": [
    "## Identify Entities Requiring Refinement\n",
    "\n",
    "Extract entities flagged for diagnostic specificity refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4503a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_refinement_candidates(normalized_dict):\n",
    "    \"\"\"\n",
    "    Extract entities that need refinement.\n",
    "    \n",
    "    Args:\n",
    "        normalized_dict (dict): Normalized entities\n",
    "        \n",
    "    Returns:\n",
    "        list: Entities needing refinement\n",
    "    \"\"\"\n",
    "    refinement_candidates = []\n",
    "    \n",
    "    for category, entity_list in normalized_dict.items():\n",
    "        for entity in entity_list:\n",
    "            if entity.get('is_refinable', False) or entity.get('needs_refinement', False):\n",
    "                refinement_candidates.append({\n",
    "                    'category': category,\n",
    "                    'entity': entity\n",
    "                })\n",
    "    \n",
    "    return refinement_candidates\n",
    "\n",
    "# Extract refinement candidates\n",
    "refinement_candidates = extract_refinement_candidates(normalized_entities)\n",
    "\n",
    "print(f\"Entities Requiring Refinement: {len(refinement_candidates)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, item in enumerate(refinement_candidates, 1):\n",
    "    entity = item['entity']\n",
    "    category = item['category']\n",
    "    print(f\"\\n{i}. {entity['text']}\")\n",
    "    print(f\"   Category: {category}\")\n",
    "    print(f\"   IMO Code: {entity.get('imo_lexical_code', 'N/A')}\")\n",
    "    print(f\"   IMO Title: {entity.get('imo_lexical_title', 'N/A')}\")\n",
    "    if entity.get('icd10cm_code'):\n",
    "        print(f\"   ICD-10-CM: {entity.get('icd10cm_code', 'N/A')} - {entity.get('icd10cm_title', 'N/A')}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "if not refinement_candidates:\n",
    "    print(\"\\n✓ All entities are sufficiently specific - no refinement needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e16f3c",
   "metadata": {},
   "source": [
    "## Save Normalized Entities\n",
    "\n",
    "Save the normalized and enriched entities for use in Step 4 (Diagnostic Specificity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output structure\n",
    "normalization_output = {\n",
    "    'normalized_entities': normalized_entities,\n",
    "    'refinement_candidates': refinement_candidates,\n",
    "    'normalization_metadata': {\n",
    "        'total_entities': sum(len(v) for v in normalized_entities.values()),\n",
    "        'successfully_normalized': sum(1 for entities in normalized_entities.values() \n",
    "                                       for e in entities if e.get('normalized', False)),\n",
    "        'needs_refinement': len(refinement_candidates),\n",
    "        'normalized_at': datetime.now().isoformat(),\n",
    "        'enrichment_used': True,\n",
    "        'code_systems': ['IMO', 'ICD10CM', 'CPT', 'RXNORM', 'LOINC']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "output_file = 'normalized_entities_output.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(normalization_output, f, indent=2)\n",
    "\n",
    "print(f\"✓ Normalized entities saved to: {output_file}\")\n",
    "print(f\"\\nOutput includes:\")\n",
    "print(f\"  - {normalization_output['normalization_metadata']['total_entities']} normalized entities\")\n",
    "print(f\"  - {normalization_output['normalization_metadata']['successfully_normalized']} successfully normalized\")\n",
    "print(f\"  - {normalization_output['normalization_metadata']['needs_refinement']} entities flagged for refinement\")\n",
    "print(f\"  - Standard codes: IMO, ICD-10-CM, CPT, RxNorm, LOINC\")\n",
    "print(f\"  - Enrichment data: alternate choices, refinement flags\")\n",
    "print(f\"  - Context used for problem normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf19b8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. ✓ Loaded extracted entities from Step 2\n",
    "2. ✓ Prepared entities for batch normalization\n",
    "3. ✓ Called IMO Precision Normalize API with context\n",
    "4. ✓ Normalized entities to standard terminologies\n",
    "5. ✓ Enriched entities with clinical metadata\n",
    "6. ✓ Identified entities needing refinement\n",
    "7. ✓ Saved normalized entities for diagnostic specificity workflow\n",
    "\n",
    "### Key Normalization Features\n",
    "\n",
    "- **Multi-code system mapping**: ICD-10-CM, SNOMED CT, RxNorm, LOINC\n",
    "- **Context-aware normalization**: Uses 200-char context for disambiguation\n",
    "- **Enrichment data**: Synonyms, clinical status, severity, attributes\n",
    "- **Refinement flags**: Identifies entities needing additional specificity\n",
    "- **Preferred terms**: Standardized medical terminology\n",
    "\n",
    "### Example: Normalization in Action\n",
    "\n",
    "**Input**: \"chest pain\"\n",
    "\n",
    "**Normalized Output**:\n",
    "- Preferred Term: \"Chest pain\"\n",
    "- ICD-10-CM: R07.9 - Chest pain, unspecified\n",
    "- SNOMED CT: 29857009 - Chest pain\n",
    "- Refinement Flag: TRUE\n",
    "- Refinement Reason: \"Needs laterality and specificity\"\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The normalized entities will be used in **Step 4: Diagnostic Specificity Workflow**, where we'll:\n",
    "- Process entities flagged for refinement\n",
    "- Use IMO Diagnostic Workflow API\n",
    "- Add specificity (laterality, severity, timing)\n",
    "- Generate more precise ICD-10 codes\n",
    "- Improve billing accuracy and clinical documentation\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Normalization** bridges free-text and structured data\n",
    "- **Context** significantly improves normalization accuracy\n",
    "- **Enrichment** adds valuable clinical intelligence\n",
    "- **Refinement flags** ensure diagnostic specificity\n",
    "- **Standard codes** enable interoperability across healthcare systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
