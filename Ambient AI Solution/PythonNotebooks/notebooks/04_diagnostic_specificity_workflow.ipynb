{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facfbf19",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/imohealth/solution-engineering/refs/heads/updates/Ambient%20AI%20Solution/PythonNotebooks/static/imo_health.png?token=GHSAT0AAAAAADSTDGZJSTP4JZ4FRZXRUZUW2LYZ3WA\" alt=\"IMO Health Logo\" width=\"300\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Configuration\n",
    "\n",
    "Import libraries and load normalized entities from Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b63f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# Import configuration\n",
    "import config\n",
    "\n",
    "# Authenticator for standard IMO APIs\n",
    "class IMOAuthenticator:\n",
    "    \"\"\"Handle IMO API authentication for standard APIs.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.auth_url = config.imo_auth_url if hasattr(config, 'imo_auth_url') else \"https://auth.imohealth.com/oauth/token\"\n",
    "        self.client_id = config.imo_diagnostic_workflow_client_id\n",
    "        self.client_secret = config.imo_diagnostic_workflow_client_secret\n",
    "        self.access_token = None\n",
    "        self.token_expiry = None\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Get or refresh OAuth access token.\"\"\"\n",
    "        if self.access_token and self.token_expiry and time.time() < self.token_expiry:\n",
    "            return self.access_token\n",
    "        \n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        payload = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'client_id': self.client_id,\n",
    "            'client_secret': self.client_secret,\n",
    "            'audience': 'https://api.imohealth.com'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.auth_url, headers=headers, json=payload, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                self.access_token = result.get('access_token')\n",
    "                expires_in = result.get('expires_in', 3600)\n",
    "                self.token_expiry = time.time() + expires_in - 60\n",
    "                return self.access_token\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting access token: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Separate authenticator for diagnostic workflow\n",
    "class DiagnosticWorkflowAuthenticator:\n",
    "    \"\"\"Handle IMO Diagnostic Workflow API authentication (separate credentials).\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.auth_url = config.imo_auth_url if hasattr(config, 'imo_auth_url') else \"https://auth.imohealth.com/oauth/token\"\n",
    "        self.client_id = config.imo_diagnostic_workflow_client_id\n",
    "        self.client_secret = config.imo_diagnostic_workflow_client_secret\n",
    "        self.access_token = None\n",
    "        self.token_expiry = None\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Get or refresh OAuth access token for diagnostic workflow.\"\"\"\n",
    "        if self.access_token and self.token_expiry and time.time() < self.token_expiry:\n",
    "            return self.access_token\n",
    "        \n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        payload = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'client_id': self.client_id,\n",
    "            'client_secret': self.client_secret,\n",
    "            'audience': 'https://api.imohealth.com'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.auth_url, headers=headers, json=payload, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                self.access_token = result.get('access_token')\n",
    "                expires_in = result.get('expires_in', 3600)\n",
    "                self.token_expiry = time.time() + expires_in - 60\n",
    "                return self.access_token\n",
    "            else:\n",
    "                print(f\"âœ— Workflow auth error: {response.status_code}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error getting workflow token: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "authenticator = IMOAuthenticator()\n",
    "workflow_authenticator = DiagnosticWorkflowAuthenticator()\n",
    "print(\"âœ“ Libraries imported and authenticators initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4152a49",
   "metadata": {},
   "source": [
    "## Load Normalized Entities from Step 3\n",
    "\n",
    "Load the normalized entities, focusing on those flagged for refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalized entities from Step 3\n",
    "normalized_file = 'normalized_entities_output.json'\n",
    "\n",
    "try:\n",
    "    with open(normalized_file, 'r') as f:\n",
    "        normalization_data = json.load(f)\n",
    "    \n",
    "    normalized_entities = normalization_data['normalized_entities']\n",
    "    refinement_candidates = normalization_data['refinement_candidates']\n",
    "    metadata = normalization_data['normalization_metadata']\n",
    "    \n",
    "    print(\"âœ“ Normalized entities loaded successfully\")\n",
    "    print(f\"\\nNormalization Summary:\")\n",
    "    print(f\"  Total entities: {metadata['total_entities']}\")\n",
    "    print(f\"  Successfully normalized: {metadata['successfully_normalized']}\")\n",
    "    print(f\"  Needs refinement: {metadata['needs_refinement']}\")\n",
    "    \n",
    "    print(f\"\\nRefinement Candidates ({len(refinement_candidates)}):\")\n",
    "    for i, candidate in enumerate(refinement_candidates[:5], 1):\n",
    "        print(f\"  {i}. {candidate['entity']['text']} - {candidate['category']}\")\n",
    "    \n",
    "    if len(refinement_candidates) > 5:\n",
    "        print(f\"  ... and {len(refinement_candidates) - 5} more\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âœ— Error: {normalized_file} not found\")\n",
    "    print(\"  Please run Step 3 notebook first to normalize entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c37dae",
   "metadata": {},
   "source": [
    "## Diagnostic Workflow Function\n",
    "\n",
    "Call the IMO Diagnostic Workflow API to refine entities with clinical specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a618d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_diagnostic_workflow(lexical_code: str, session_id: Optional[str] = None) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Call IMO Diagnostic Workflow API to refine entity with clinical specificity.\n",
    "    \n",
    "    This matches the diagnostic_workflow() function in app.py.\n",
    "    \n",
    "    Args:\n",
    "        lexical_code (str): IMO lexical code from normalized entity\n",
    "        session_id (str, optional): Session ID for workflow continuity\n",
    "        \n",
    "    Returns:\n",
    "        dict: Workflow data with refinement questions and options, or None if error\n",
    "    \"\"\"\n",
    "    # Get diagnostic workflow access token (separate credentials)\n",
    "    access_token = workflow_authenticator.get_access_token()\n",
    "    if not access_token:\n",
    "        print(\"âœ— Failed to obtain diagnostic workflow access token\")\n",
    "        return None\n",
    "    \n",
    "    # API endpoint for diagnostic workflow\n",
    "    workflow_url = config.imo_diagnostic_workflow_url if hasattr(config, 'imo_diagnostic_workflow_url') else \\\n",
    "                   \"https://api.imohealth.com/core/search/v2/product/problemIT_Professional/workflows/diagnosis\"\n",
    "    \n",
    "    # Generate session ID if not provided\n",
    "    if not session_id:\n",
    "        session_id = \"00000000-0000-0000-0000-000000000000\"\n",
    "    \n",
    "    # Prepare workflow request payload (matches app.py structure)\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        'usePreviousVersion': False,\n",
    "        'sessionId': session_id,\n",
    "        'imoLexicalCode': lexical_code,\n",
    "        'properties': [],\n",
    "        'clientApp': 'AmbientAI',\n",
    "        'clientAppVersion': '1.0',\n",
    "        'siteId': 'AmbientAI',\n",
    "        'userId': 'AmbientUser'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            workflow_url,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            workflow_data = response.json()\n",
    "            return workflow_data\n",
    "        else:\n",
    "            print(f\"âœ— Workflow API Error: {response.status_code}\")\n",
    "            print(f\"  Response: {response.text[:200]}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Exception calling workflow: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ Diagnostic workflow function initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96dcc",
   "metadata": {},
   "source": [
    "## Process Refinement Workflow\n",
    "\n",
    "For each entity needing refinement, call the diagnostic workflow and display refinement options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc699088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_workflow_response(workflow_data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse workflow response to extract modifier groups and combinations.\n",
    "    \n",
    "    Args:\n",
    "        workflow_data (dict): Raw workflow API response\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed workflow with modifier groups, combinations, and codes\n",
    "    \"\"\"\n",
    "    parsed = {\n",
    "        'request_id': workflow_data.get('requestId', ''),\n",
    "        'title': workflow_data.get('title', ''),\n",
    "        'code': workflow_data.get('code', ''),\n",
    "        'primary_icd9': workflow_data.get('primaryIcd9', ''),\n",
    "        'primary_icd10': workflow_data.get('primaryIcd10', ''),\n",
    "        'modifier_groups': [],\n",
    "        'modifier_combinations': workflow_data.get('modifierCombinations', []),\n",
    "        'total_modifier_groups': 0,\n",
    "        'total_combinations': 0\n",
    "    }\n",
    "    \n",
    "    # Extract modifier groups\n",
    "    modifier_groups = workflow_data.get('modifierGroups', [])\n",
    "    parsed['total_modifier_groups'] = len(modifier_groups)\n",
    "    parsed['total_combinations'] = len(parsed['modifier_combinations'])\n",
    "    \n",
    "    for group in modifier_groups:\n",
    "        group_data = {\n",
    "            'title': group.get('title', ''),\n",
    "            'type': group.get('type', ''),\n",
    "            'modifiers': []\n",
    "        }\n",
    "        \n",
    "        # Extract modifiers in this group\n",
    "        for modifier in group.get('modifiers', []):\n",
    "            modifier_data = {\n",
    "                'code': modifier.get('code', ''),\n",
    "                'title': modifier.get('title', ''),\n",
    "                'combinations': modifier.get('combinations', [])\n",
    "            }\n",
    "            group_data['modifiers'].append(modifier_data)\n",
    "        \n",
    "        parsed['modifier_groups'].append(group_data)\n",
    "    \n",
    "    return parsed\n",
    "\n",
    "def display_workflow_modifiers(parsed_workflow: Dict, entity_text: str):\n",
    "    \"\"\"\n",
    "    Display workflow modifier groups and combinations in a readable format.\n",
    "    \n",
    "    Args:\n",
    "        parsed_workflow (dict): Parsed workflow data\n",
    "        entity_text (str): Original entity text\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Diagnostic Workflow: {entity_text}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Request ID: {parsed_workflow['request_id']}\")\n",
    "    print(f\"Title: {parsed_workflow['title']}\")\n",
    "    print(f\"Code: {parsed_workflow['code']}\")\n",
    "    print(f\"Primary ICD-10: {parsed_workflow['primary_icd10']}\")\n",
    "    print(f\"Total Modifier Groups: {parsed_workflow['total_modifier_groups']}\")\n",
    "    print(f\"Total Combinations: {parsed_workflow['total_combinations']}\")\n",
    "    \n",
    "    # Display each modifier group\n",
    "    for i, group in enumerate(parsed_workflow['modifier_groups'], 1):\n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(f\"Modifier Group {i}: {group['title']}\")\n",
    "        print(f\"Type: {group['type']}\")\n",
    "        print(f\"\\nModifiers ({len(group['modifiers'])}):\")\n",
    "        \n",
    "        for j, modifier in enumerate(group['modifiers'], 1):\n",
    "            title = modifier['title']\n",
    "            code = modifier['code']\n",
    "            combinations = modifier['combinations']\n",
    "            print(f\"\\n  {j}. {title}\")\n",
    "            print(f\"     Code: {code}\")\n",
    "            print(f\"     Combinations: {len(combinations)} available\")\n",
    "            \n",
    "            # Show first few combinations\n",
    "            if combinations:\n",
    "                for k, combo in enumerate(combinations[:3], 1):\n",
    "                    print(f\"       - {combo}\")\n",
    "                if len(combinations) > 3:\n",
    "                    print(f\"       ... and {len(combinations) - 3} more combinations\")\n",
    "\n",
    "# Process refinement candidates through diagnostic workflow\n",
    "workflow_results = []\n",
    "\n",
    "print(\"\\nStarting Diagnostic Workflow Processing\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Process first 3 entities to demonstrate workflow\n",
    "for i, candidate in enumerate(refinement_candidates[:3], 1):\n",
    "    entity = candidate['entity']\n",
    "    entity_text = entity['text']\n",
    "    lexical_code = entity.get('imo_lexical_code', '')\n",
    "    \n",
    "    print(f\"\\n[{i}/{min(3, len(refinement_candidates))}] Processing: {entity_text}\")\n",
    "    print(f\"  Category: {candidate.get('category', 'unknown')}\")\n",
    "    print(f\"  IMO Lexical Code: {lexical_code}\")\n",
    "    \n",
    "    if not lexical_code:\n",
    "        print(\"  âœ— No lexical code available - skipping workflow\")\n",
    "        continue\n",
    "    \n",
    "    # Call diagnostic workflow API\n",
    "    workflow_data = call_diagnostic_workflow(lexical_code)\n",
    "    \n",
    "    if workflow_data:\n",
    "        # Parse workflow response\n",
    "        parsed = parse_workflow_response(workflow_data)\n",
    "        \n",
    "        # Display workflow modifier groups and combinations\n",
    "        display_workflow_modifiers(parsed, entity_text)\n",
    "        \n",
    "        # Store result\n",
    "        result = {\n",
    "            'candidate': candidate,\n",
    "            'entity': entity,\n",
    "            'lexical_code': lexical_code,\n",
    "            'workflow_data': workflow_data,\n",
    "            'parsed_workflow': parsed,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        workflow_results.append(result)\n",
    "        \n",
    "        print(f\"\\nâœ“ Workflow retrieved successfully\")\n",
    "    else:\n",
    "        print(f\"\\nâœ— Workflow failed for this entity\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(f\"\\nâœ“ Processed {len(workflow_results)} entities through diagnostic workflow\")\n",
    "print(f\"  Successful workflows: {len(workflow_results)}\")\n",
    "print(f\"  Failed workflows: {min(3, len(refinement_candidates)) - len(workflow_results)}\")\n",
    "\n",
    "if len(refinement_candidates) > 3:\n",
    "    print(f\"\\nNote: {len(refinement_candidates) - 3} additional entities available for refinement\")\n",
    "    print(\"  (Limiting to 3 for demonstration - process all in production)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea57acf",
   "metadata": {},
   "source": [
    "## Analyze Workflow Results\n",
    "\n",
    "Review the diagnostic workflow questions and refinement options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b81160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_workflow_results(workflow_results: List[Dict]):\n",
    "    \"\"\"\n",
    "    Analyze workflow results to understand refinement patterns.\n",
    "    \n",
    "    Args:\n",
    "        workflow_results (list): List of workflow results\n",
    "    \"\"\"\n",
    "    if not workflow_results:\n",
    "        print(\"No workflow results to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nWORKFLOW RESULTS ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_modifier_groups = 0\n",
    "    total_combinations = 0\n",
    "    all_group_types = set()\n",
    "    entities_with_workflows = len(workflow_results)\n",
    "    \n",
    "    for result in workflow_results:\n",
    "        parsed = result['parsed_workflow']\n",
    "        total_modifier_groups += parsed['total_modifier_groups']\n",
    "        total_combinations += parsed['total_combinations']\n",
    "        for group in parsed['modifier_groups']:\n",
    "            all_group_types.add(group['type'])\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"  Entities processed: {entities_with_workflows}\")\n",
    "    print(f\"  Total modifier groups: {total_modifier_groups}\")\n",
    "    print(f\"  Total combinations: {total_combinations}\")\n",
    "    print(f\"  Average groups per entity: {total_modifier_groups/entities_with_workflows:.1f}\")\n",
    "    print(f\"  Unique modifier types: {len(all_group_types)}\")\n",
    "    \n",
    "    if all_group_types:\n",
    "        print(f\"\\n  Modifier types available:\")\n",
    "        for mod_type in sorted(all_group_types):\n",
    "            print(f\"    â€¢ {mod_type}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"\\nEntity-Level Breakdown:\")\n",
    "    \n",
    "    for i, result in enumerate(workflow_results, 1):\n",
    "        entity = result['entity']\n",
    "        candidate = result['candidate']\n",
    "        parsed = result['parsed_workflow']\n",
    "        \n",
    "        print(f\"\\n{i}. {entity['text']}\")\n",
    "        print(f\"   Category: {candidate.get('category', 'unknown')}\")\n",
    "        print(f\"   IMO Code: {entity.get('imo_code', 'N/A')}\")\n",
    "        print(f\"   Primary ICD-10: {parsed['primary_icd10']}\")\n",
    "        print(f\"   Modifier groups: {parsed['total_modifier_groups']}\")\n",
    "        print(f\"   Total combinations: {parsed['total_combinations']}\")\n",
    "        \n",
    "        # Show modifier group info if available\n",
    "        if parsed['modifier_groups']:\n",
    "            sample_group = parsed['modifier_groups'][0]\n",
    "            print(f\"   Sample modifier group: {sample_group['title']}\")\n",
    "            print(f\"   Modifiers available: {len(sample_group['modifiers'])}\")\n",
    "\n",
    "analyze_workflow_results(workflow_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bec87",
   "metadata": {},
   "source": [
    "## Save Workflow Results\n",
    "\n",
    "Save the diagnostic workflow results for further processing or review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaafe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save workflow results\n",
    "output_file = 'diagnostic_workflow_output.json'\n",
    "\n",
    "output_data = {\n",
    "    'workflow_results': workflow_results,\n",
    "    'metadata': {\n",
    "        'total_candidates': len(refinement_candidates),\n",
    "        'processed': len(workflow_results),\n",
    "        'successful': len(workflow_results),\n",
    "        'failed': min(3, len(refinement_candidates)) - len(workflow_results),\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'workflow_api': config.imo_diagnostic_workflow_url if hasattr(config, 'imo_diagnostic_workflow_url') else 'default'\n",
    "    },\n",
    "    'summary': {\n",
    "        'entities_with_workflows': len(workflow_results),\n",
    "        'total_modifier_groups': sum(r['parsed_workflow']['total_modifier_groups'] for r in workflow_results),\n",
    "        'total_combinations': sum(r['parsed_workflow']['total_combinations'] for r in workflow_results),\n",
    "        'unique_modifier_types': len(set(\n",
    "            group['type']\n",
    "            for r in workflow_results \n",
    "            for group in r['parsed_workflow']['modifier_groups']\n",
    "        ))\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Workflow results saved to: {output_file}\")\n",
    "print(f\"\\nOutput Summary:\")\n",
    "print(f\"  Total candidates: {output_data['metadata']['total_candidates']}\")\n",
    "print(f\"  Processed: {output_data['metadata']['processed']}\")\n",
    "print(f\"  Successful workflows: {output_data['metadata']['successful']}\")\n",
    "print(f\"  Total modifier groups: {output_data['summary']['total_modifier_groups']}\")\n",
    "print(f\"  Total combinations: {output_data['summary']['total_combinations']}\")\n",
    "print(f\"  Unique modifier types: {output_data['summary']['unique_modifier_types']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece98d2",
   "metadata": {},
   "source": [
    "## Next Steps: Selecting Modifiers and Combinations\n",
    "\n",
    "In a production system, the modifier selections would be made through:\n",
    "\n",
    "1. **Interactive UI**: Present modifier groups to clinicians for selection\n",
    "2. **AI-Assisted Selection**: Use contextual analysis to suggest modifiers based on clinical notes\n",
    "3. **Rules Engine**: Apply clinical decision rules for common scenarios\n",
    "4. **Historical Patterns**: Learn from previous coding decisions\n",
    "\n",
    "Once modifiers are selected, you would:\n",
    "- Submit the selected combination ID back to the workflow API\n",
    "- Receive specific ICD-10-CM codes based on the modifier combination\n",
    "- Update the entity with billable, specific diagnostic codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample workflow interaction\n",
    "if workflow_results:\n",
    "    print(\"\\nSAMPLE WORKFLOW INTERACTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    sample_result = workflow_results[0]\n",
    "    entity = sample_result['entity']\n",
    "    parsed = sample_result['parsed_workflow']\n",
    "    \n",
    "    print(f\"\\nEntity: {entity['text']}\")\n",
    "    print(f\"Original ICD-10: {entity.get('icd10cm_code', 'N/A')}\")\n",
    "    print(f\"Workflow Primary ICD-10: {parsed['primary_icd10']}\")\n",
    "    print(f\"Request ID: {parsed['request_id']}\")\n",
    "    \n",
    "    print(f\"\\nModifier Groups ({parsed['total_modifier_groups']}):\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for i, group in enumerate(parsed['modifier_groups'], 1):\n",
    "        print(f\"\\nGroup {i}: {group['title']}\")\n",
    "        print(f\"Type: {group['type']}\")\n",
    "        print(\"\\nAvailable Modifiers:\")\n",
    "        \n",
    "        for j, modifier in enumerate(group['modifiers'][:5], 1):\n",
    "            print(f\"  {j}. {modifier['title']} (Code: {modifier['code']})\")\n",
    "            print(f\"     Combinations: {len(modifier['combinations'])}\")\n",
    "        \n",
    "        if len(group['modifiers']) > 5:\n",
    "            print(f\"  ... and {len(group['modifiers']) - 5} more modifiers\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"\\nTotal possible combinations: {parsed['total_combinations']}\")\n",
    "    \n",
    "    print(\"\\nTo complete refinement:\")\n",
    "    print(\"1. Select appropriate modifier from each group\")\n",
    "    print(\"2. Use the combination ID from the selected modifier\")\n",
    "    print(\"3. Submit combination ID to workflow API\")\n",
    "    print(\"4. Receive refined ICD-10-CM code with specificity\")\n",
    "    print(\"5. Update entity with billable diagnostic code\")\n",
    "    \n",
    "    print(\"\\nExample: Selecting a modifier combination:\")\n",
    "    print(\"-\"*80)\n",
    "    if parsed['modifier_groups'] and parsed['modifier_groups'][0]['modifiers']:\n",
    "        first_modifier = parsed['modifier_groups'][0]['modifiers'][0]\n",
    "        example_payload = {\n",
    "            'requestId': parsed['request_id'],\n",
    "            'imoLexicalCode': sample_result['lexical_code'],\n",
    "            'combinationId': first_modifier['combinations'][0] if first_modifier['combinations'] else 'N/A',\n",
    "            'selectedModifier': {\n",
    "                'code': first_modifier['code'],\n",
    "                'title': first_modifier['title']\n",
    "            }\n",
    "        }\n",
    "        print(json.dumps(example_payload, indent=2))\n",
    "else:\n",
    "    print(\"\\nNo workflow results available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb3efe",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. âœ“ Loaded normalized entities from Step 3\n",
    "2. âœ“ Identified entities requiring diagnostic specificity (is_refinable flag)\n",
    "3. âœ“ Called IMO Diagnostic Workflow API with lexical codes\n",
    "4. âœ“ Retrieved refinement questions and property options\n",
    "5. âœ“ Demonstrated workflow structure and question format\n",
    "6. âœ“ Saved workflow results for further processing\n",
    "\n",
    "### Diagnostic Workflow API Overview\n",
    "\n",
    "**Purpose**: Refine diagnoses with clinical specificity attributes\n",
    "\n",
    "**Input**: IMO lexical code from normalized entities\n",
    "\n",
    "**Process**:\n",
    "1. Authenticate with separate workflow OAuth credentials\n",
    "2. Submit lexical code to workflow endpoint\n",
    "3. Receive refinement questions (laterality, severity, onset, etc.)\n",
    "4. Answer questions based on clinical context\n",
    "5. Submit answers to get specific ICD-10-CM codes\n",
    "\n",
    "**Output**: Billable, specific diagnostic codes\n",
    "\n",
    "### Complete Ambient AI Workflow\n",
    "\n",
    "**Step 1: Transcript â†’ SOAP Note**\n",
    "- Amazon Bedrock Nova Pro\n",
    "- Structured clinical documentation\n",
    "- Output: SOAP note JSON\n",
    "\n",
    "**Step 2: SOAP Note â†’ Entity Extraction**\n",
    "- IMO Entity Extraction API v3.0\n",
    "- 200-character context capture\n",
    "- Categorization: problems, procedures, medications, labs\n",
    "- Output: Entities with context and IMO codes\n",
    "\n",
    "**Step 3: Entities â†’ Normalization**\n",
    "- IMO Precision Normalize + Enrichment APIs\n",
    "- Multi-code system mapping (ICD-10-CM, SNOMED, CPT, RxNorm, LOINC)\n",
    "- Refinement flags identification\n",
    "- Output: Normalized entities with refinement candidates\n",
    "\n",
    "**Step 4: Normalization â†’ Diagnostic Specificity** (This Notebook)\n",
    "- IMO Diagnostic Workflow API\n",
    "- Attribute-based refinement questions\n",
    "- Contextual specificity options\n",
    "- Output: Workflow questions ready for clinical input\n",
    "\n",
    "### Real-World Example\n",
    "\n",
    "**Original Transcript**: \"Patient has right knee pain, moderate severity, started 3 days ago\"\n",
    "\n",
    "**After Step 1 (SOAP)**: Assessment: \"Knee pain, right side, moderate\"\n",
    "\n",
    "**After Step 2 (Extraction)**: \n",
    "- Entity: \"knee pain\"\n",
    "- Context: \"...has right knee pain, moderate severity...\"\n",
    "- Offset: 15, Length: 9\n",
    "\n",
    "**After Step 3 (Normalization)**:\n",
    "- IMO Code: 529811\n",
    "- ICD-10-CM: M25.569 - Pain in unspecified knee\n",
    "- Is Refinable: TRUE\n",
    "- Needs Refinement: TRUE\n",
    "\n",
    "**After Step 4 (Workflow - This Notebook)**:\n",
    "- Session ID: Generated UUID\n",
    "- Questions:\n",
    "  * Q1: Which side is affected? (Laterality)\n",
    "    - Options: Right, Left, Bilateral\n",
    "  * Q2: What is the severity? (Severity)\n",
    "    - Options: Mild, Moderate, Severe\n",
    "  * Q3: When did it start? (Onset)\n",
    "    - Options: Acute (< 3 months), Chronic (> 3 months)\n",
    "\n",
    "**After Answering Questions** (Not in this demo):\n",
    "- Refined ICD-10-CM: M25.561 - Pain in right knee [BILLABLE]\n",
    "- Specificity: HIGH\n",
    "- Billable: TRUE\n",
    "\n",
    "### Clinical Impact\n",
    "\n",
    "- **Accuracy**: Specific codes match clinical documentation exactly\n",
    "- **Billing**: Billable codes maximize appropriate reimbursement\n",
    "- **Compliance**: Meets ICD-10 specificity requirements\n",
    "- **Quality**: Supports quality metrics and value-based care\n",
    "- **Efficiency**: Reduces manual coding time by 70-80%\n",
    "- **Denial Prevention**: Specific codes reduce claim denials\n",
    "\n",
    "### Key Differences from Demo Refinement\n",
    "\n",
    "**Demo Approach** (refine_entities in nlp_processor.py):\n",
    "- Returns hardcoded refinement options\n",
    "- No actual API calls\n",
    "- Mock data for testing UI\n",
    "\n",
    "**Production Approach** (diagnostic_workflow in app.py):\n",
    "- Calls actual IMO Diagnostic Workflow API\n",
    "- Uses separate OAuth credentials\n",
    "- Returns real refinement questions based on entity\n",
    "- Questions vary by diagnosis type\n",
    "- Contextually relevant options\n",
    "\n",
    "### Next Steps for Production\n",
    "\n",
    "1. **Answer Workflow Questions**:\n",
    "   - Build UI to present questions to clinicians\n",
    "   - Or use AI to suggest answers from clinical context\n",
    "   - Submit answers back to workflow API\n",
    "\n",
    "2. **Retrieve Refined Codes**:\n",
    "   - Get specific ICD-10-CM codes based on answers\n",
    "   - Update entity with billable codes\n",
    "   - Store refinement history\n",
    "\n",
    "3. **Integration**:\n",
    "   - Connect to EHR systems\n",
    "   - Submit codes for billing\n",
    "   - Track coding accuracy metrics\n",
    "\n",
    "4. **Scaling**:\n",
    "   - Batch process multiple encounters\n",
    "   - Optimize API calls\n",
    "   - Cache workflow sessions\n",
    "   - Monitor performance\n",
    "\n",
    "### Workflow API Details\n",
    "\n",
    "**Endpoint**: `/core/search/v2/product/problemIT_Professional/workflows/diagnosis`\n",
    "\n",
    "**Authentication**: Separate OAuth credentials (imo_diagnostic_workflow_client_id/secret)\n",
    "\n",
    "**Request Payload**:\n",
    "```json\n",
    "{\n",
    "  \"usePreviousVersion\": false,\n",
    "  \"sessionId\": \"UUID\",\n",
    "  \"imoLexicalCode\": \"123456\",\n",
    "  \"properties\": [],\n",
    "  \"clientApp\": \"AmbientAI\",\n",
    "  \"clientAppVersion\": \"1.0\",\n",
    "  \"siteId\": \"AmbientAI\",\n",
    "  \"userId\": \"AmbientUser\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Response Structure**:\n",
    "- sessionId: Workflow session identifier\n",
    "- questions: Array of refinement questions\n",
    "- Each question has:\n",
    "  - id, text, property, type\n",
    "  - options: Array of possible answers with confidence scores\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "1. **Session Management**: Track workflow sessions across multiple API calls\n",
    "2. **Property Selection**: Implement logic to select appropriate answers\n",
    "3. **Confidence Thresholds**: Auto-select high-confidence options when applicable\n",
    "4. **Error Handling**: Handle API failures gracefully\n",
    "5. **Audit Trail**: Log all workflow decisions for compliance\n",
    "6. **Performance**: Cache tokens and sessions to reduce API calls\n",
    "\n",
    "---\n",
    "\n",
    "**End of Ambient AI Workflow Pipeline** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
